"""
    Crawly - URL Crawler written in Python.

    Jordan Zdimirovic. https://github.com/jordstar20001/crawly
"""

# Import dependencies
import requests, json, pandas as pd, numpy as np
from schema import Schema, And, Use, Optional, SchemaError

OPTIONS_SCHEMA = Schema({
    # Max depth is default 0 (infinity), but must be 0 or positive
    Optional("max_depth", default=0): And(int, lambda x: x >= 0),

    # All source pages must have http / https, and must be strings. Must be at least one src
    "source_pages": And([str], lambda lst: len(lst) > 0 and all([map(v.startswith, ["http", "https"]) for v in lst])),

    # Asynchronous crawling?
    Optional("async", default=False): bool,

    # Export data to csv?
    Optional("csv_export", default=None): str,

    # Get geolocation data?
    Optional("geolocational", default=False): bool
})

# Default Crawly exception
class CrawlyException(Exception): pass

def get_default_crawly_options():
    """
        Returns the default options that must be provided to the CrawlyCrawler constructor.
    """
    options = {
        "max_depth": 100
    }

    if not OPTIONS_SCHEMA.is_valid(options):
        raise CrawlyException(
            "Default options did not match the required schema.\nPlease check the source code or raise an issue on the GitHub."
        )

    return options


class CrawlyCrawler():
    def __init__(self, **kwa):
        """
            Crawly Crawler constructor.

            Keyword Arguments:
            * *options* (``dict``) --
            Provide options similar to that generated by `get_default_crawly_options()`.
            * *config* (``str``) --
            Provide a file path to a stored option JSON formatted file.
        """
        # Both options and config are not allowed
        assert not ("options" in kwa and "config" in kwa), "Cannot provide both an options dictionary and a config file"

        if "options" in kwa:
            self.options = kwa["options"]
        
        elif "config" in kwa:
            try:
                with open(kwa["config"]) as f:
                    self.options = json.loads(f.read())
            
            except FileNotFoundError:
                raise CrawlyException(f"Config file at '{kwa['config']}' was not found.")
            
            except json.decoder.JSONDecodeError:
                raise CrawlyException(f"Config file was invalid.")
        
        else:
            self.options = get_default_crawly_options()

        try:
            self.options = OPTIONS_SCHEMA.validate(self.options)

        except SchemaError as e:
            raise CrawlyException(f"Options were not valid.\n{e}")

        self.setup()

<<<<<<< HEAD
    def setup(self):
=======
    def setup():
>>>>>>> 823eb2ee34f23752161e836b994b53041a7e76dc
        """
            Perform operations to setup the crawling process
        """
        pass

    def start(self):
        """
            Begin the crawling process
        """
        pass
